# 2024-04-15勉強会<br>オリエンテーション + The Annotated Transformer①
## 概要
- 2024-04-15実施の勉強会についての資料です。<br>
- resoucesフォルダに勉強会で用いる資料を掲載しています。適宜参照してください。<br>
- programフォルダには勉強会でコーディング予定のプログラムを置いているので、適宜参照してください。<br>

## 参考文献一覧
[1] Austin Huang, Suraj Subramanian, Jonathan Sum, Khalid Almubarak, and Stella Biderman(2022). The Annotated Transformer. https://nlp.seas.harvard.edu/annotated-transformer/<br>
[2] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser(2017). Attention Is All You Need. Advances in Neural Information Processing Systems 30 (NIPS 2017)<br>
[3] 森下篤(2024). Visual Studio Code 実践ガイド. 技術評論社<br>
[4] Bill Ludanovic, 鈴木駿, 長尾高弘(2022). 入門 Python3 第二版. O'Reilly Japan<br>
[5] Al Sweigart, 相川愛三(2023). 退屈なことはPythonにやらせよう　第二版. O'Reilly Japan<br>
[6] Al Sweigart, 岡田祐一(2022). きれいなPythonプログラミング. マイナビ<br>

## 更新履歴
2025.04.09 first commit<br>
2025.04.09 update readme(add structure of readme)<br>
2025.04.09 fix format of reference<br>
2025.04.09 add program folder and update readme<br>
2025.04.10 update readme<br>
2025.04.10 refrect the opinion of yoshiteru<br>
2025.04.10 README.md is decomposed into /resouces/orientation.md and /resouces/TheAnnotatedTransformer1.md.<br>
2025.04.10 add orientation.pdf<br>
2025.04.12 refrect the opinion of Dr.shota<br>

This material benefited from the assistance of ChatGPT.

Kazuma Aoyama(kazuma-a@lsnl.jp), Yoshiteru Taira(yohsiteru@lsnl.jp) and Shota Inoue(shota@lsnl.jp)
