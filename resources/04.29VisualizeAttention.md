## 2025.04.29 Visualize Attention
## 前回の振り返り & 導入
### The Annotated Transformerは難しかった
- 前回は"The Annotated Transformer"という有名な教材に従って、Transformerを実装しながら学ぼうとした。<br>
- 内容が難しすぎた。モデルの話は前提知識が無いと理解不能。<br>
- 70分ぐらいやって全体の5%ぐらいしか進めなかった<br>
- 図やイラストが無く、文章だけで理解するのは難しい<br>
- 聴講者の反応も重かった<br>
という反省を活かして・・・
### 今回は視覚的にわかる・面白い・軽めな内容
「もっと視覚的に」「もっと楽しく」学ぶことを目指します！<br>
テーマ：Attention を可視化して直感的に理解する<br>
### "Attention"って結局何をしてるのか・何者なのかを体感する
具体的には、Attentionという仕組み[[1]](http://github.com/jessevig/bertviz)を、可視化ツールを使って実際に見ながら学んでいく<br>
今日のゴールは、「Attentionってこういう風に働いているんだな」というイメージを持つこと<br>
## そもそも、Attention とは何か
### Attentionイメージ図
【単語列】（大きめ）
The       cat        sat       on       the       mat

【矢印列】（注目度に応じた太さ・色）
 ↓         ⇩         ★        ↓         ↓         ⇩

【注目コメント列】（小さく下に）
(弱い)   (強い)  (中心)  (弱い) (弱い) (やや強い)

## 参考文献
[1] http://github.com/jessevig/bertviz